{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alkB9IXjamJ8"
   },
   "source": [
    "**Download the sample provided data with image and ground truth into the working directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vfP6WIPav9Y",
    "outputId": "3f262513-96de-42f9-ea0b-f9f4540b1343"
   },
   "outputs": [],
   "source": [
    "!mkdir Dataset\n",
    "!wget  https://zenodo.org/records/12723317/files/Image.tif?download=1  -O Dataset/Image.tif\n",
    "!wget  https://zenodo.org/records/12723317/files/GT.gpkg?download=1 -O Dataset/GT.gpkg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klBwmDZfbS2d"
   },
   "source": [
    "**Install Libraries that are not present in colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ht_IBlwMbZMt",
    "outputId": "a66e3ef9-254d-4116-f2e7-757a196b2a07"
   },
   "outputs": [],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XC1zym9Eawy7"
   },
   "source": [
    "**Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fj43jeeeueR"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure\n",
    "import geopandas as gpd\n",
    "from rasterio import features\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgffcMwSbh9f"
   },
   "source": [
    "**Load the satellite image from downloaded directory and check it for its properties as well as quality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-sSeBMfMZSoh"
   },
   "outputs": [],
   "source": [
    "src = rasterio.open(\"Dataset/Image.tif\")\n",
    "img = src.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pcg3QBKDcah0",
    "outputId": "0fbd5553-3037-439b-b0d4-4eb1e4ab3329"
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mumlWb6cgnq"
   },
   "source": [
    "It shows that there are five bands which is B02, B03, B04, B08 and B012. This is used in the training but for visualization we only need bands 2,3,4 in 4,3,2 sequence. Now lets make that change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HioBozphcf_7"
   },
   "outputs": [],
   "source": [
    "img_vis = img[[4, 3, 2], :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lExpcjqMc6V7"
   },
   "source": [
    "Let's plot the image to see how does it look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "0on-lZ1yc5iv",
    "outputId": "b1d814bd-87a6-48e7-b327-3e8c85e3618c"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "show(img_vis, transform=src.transform, ax=ax)\n",
    "ax.ticklabel_format(useOffset=False, style=\"plain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ApLiRmBetlg"
   },
   "source": [
    "The image looks too dark, so let's enhance it a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvQHh1V2etOV"
   },
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    for i in range(arr.shape[0]):\n",
    "        p5, p95 = np.percentile(arr[i, :, :], (5, 95))\n",
    "        arr[i, :, :] = exposure.rescale_intensity(\n",
    "            arr[i, :, :], in_range=(arr.min(), arr.max())\n",
    "        )\n",
    "    return arr\n",
    "\n",
    "\n",
    "img_vis_norm = normalize(img_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "id": "1SR2mZRse-0H",
    "outputId": "d9f9fde8-f13f-49ac-cf6f-8c1163d4221e"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "show(img_vis_norm, transform=src.transform, ax=ax)\n",
    "ax.ticklabel_format(useOffset=False, style=\"plain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzoyEcvTiYm3"
   },
   "source": [
    "This shows much more clearly the burnt area compared to non-burnt area. Now, lets load the ground truth data that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6eQQPnzqeUr5"
   },
   "outputs": [],
   "source": [
    "GroundTruth = gpd.read_file(\"Dataset/GT.gpkg\").to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvOZTEe8iy2U"
   },
   "source": [
    "Lets visualize it on top of the satellite image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 755
    },
    "id": "33N-t3oAirzl",
    "outputId": "5e7dd2c6-a179-446a-c197-bf686a4aa8c3"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "show(img_vis_norm, transform=src.transform, ax=ax)\n",
    "ax.ticklabel_format(useOffset=False, style=\"plain\")\n",
    "GroundTruth.plot(ax=ax, color=\"none\", edgecolor=\"red\", hatch=\"//\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcCcExILj3aF"
   },
   "source": [
    "This shows that our image and training dataset match quite well. Now, lets convert the ground truth into an image such that we can use it to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZ9HxqmVlDyC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7JNcrwIkb8d"
   },
   "outputs": [],
   "source": [
    "shapes = ((geom, 1) for geom in GroundTruth.geometry)\n",
    "raster_GT = features.rasterize(\n",
    "    shapes=shapes, fill=0, out_shape=img_vis_norm[0].shape, transform=src.transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 604
    },
    "id": "RA4fUie7kb5q",
    "outputId": "017fdd84-1014-4a5e-b325-833081e744b7"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "show(raster_GT, transform=src.transform, ax=ax)\n",
    "ax.ticklabel_format(useOffset=False, style=\"plain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17D2U0OSnmsh"
   },
   "source": [
    "Now the satellite image will serve us as the training data while the raster we just created will serve us as the ground truth. Most of the neural network models take the band as the last axis of the image instead of first, therefore let us change our image to band last format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A51Jpd1pkb2d"
   },
   "outputs": [],
   "source": [
    "XData = img.transpose((1, 2, 0))\n",
    "YData = np.expand_dims(raster_GT, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4BNnEapkUE5"
   },
   "source": [
    "Now, the neural network models often take the images as small patches. The following steps will make those patches from this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMA5oYx5iudl",
    "outputId": "132e1058-a377-4429-aa21-a8d1984de899"
   },
   "outputs": [],
   "source": [
    "PATCHSIZE = 32\n",
    "NBANDS = XData.shape[-1]\n",
    "\n",
    "\n",
    "def gridwise_sample(imgarray, patchsize):\n",
    "    \"\"\"Extract sample patches of size patchsize x patchsize from an image (imgarray) in a gridwise manner.\"\"\"\n",
    "    nrows, ncols, nbands = imgarray.shape\n",
    "    patchsamples = np.zeros(\n",
    "        shape=(0, patchsize, patchsize, nbands), dtype=imgarray.dtype\n",
    "    )\n",
    "    for i in range(int(nrows / patchsize)):\n",
    "        for j in range(int(ncols / patchsize)):\n",
    "            tocat = imgarray[\n",
    "                i * patchsize : (i + 1) * patchsize,\n",
    "                j * patchsize : (j + 1) * patchsize,\n",
    "                :,\n",
    "            ]\n",
    "            tocat = np.expand_dims(tocat, axis=0)\n",
    "            patchsamples = np.concatenate((patchsamples, tocat), axis=0)\n",
    "    return patchsamples\n",
    "\n",
    "\n",
    "XPatches = gridwise_sample(XData, PATCHSIZE)\n",
    "YPatches = gridwise_sample(YData, PATCHSIZE)\n",
    "\n",
    "print(\"There are %i number of training patches\" % (XPatches.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0OwqByYp6AZ"
   },
   "source": [
    "We have now made 350 training samples from which our model can learn. Now lets check if it is okay or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "nsUubZxFi7nS",
    "outputId": "6b68f390-812e-4731-c55d-fd0f8a64aa8a"
   },
   "outputs": [],
   "source": [
    "n = 85  # sample number\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(XPatches[n, :, :, [2, 3, 1]].transpose((0, 1, 2)))\n",
    "ax[1].imshow(YPatches[n, :, :, 0])\n",
    "\n",
    "ax[0].ticklabel_format(useOffset=False, style=\"plain\")\n",
    "ax[1].ticklabel_format(useOffset=False, style=\"plain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y71xlrXrr-lH"
   },
   "source": [
    "**Now, Lets divide this data into training and test sets randomly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZyMmphPZqGE_"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    XPatches, YPatches, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxWiYs0xvyBH",
    "outputId": "277f092f-3b3a-4ce7-dd69-015e2542d937"
   },
   "outputs": [],
   "source": [
    "print(f\"Training Set has {X_train.shape[0]} Number of samples\")\n",
    "print(f\"Test Set has {X_test.shape[0]} Number of samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_nisxRcwNZn"
   },
   "source": [
    "Now you can save this into a numpy array so that while training you can only load the array and not whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LYZGUUcwTgi"
   },
   "outputs": [],
   "source": [
    "np.save(\"Dataset/X_train.npy\", X_train)\n",
    "np.save(\"Dataset/X_test.npy\", X_test)\n",
    "np.save(\"Dataset/y_train.npy\", y_train)\n",
    "np.save(\"Dataset/y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-m8RI990wCrY"
   },
   "source": [
    "This completes the tutorial on data preparation as it provides all details on how images can be loaded and converted into the desired format."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
