{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the pre-processed data in previous data preparation notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Ground Truth\n",
    "!mkdir Dataset\n",
    "!wget  Change this link  -O Dataset/GT.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import segmentation_models as sm\n",
    "keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and divide dataset\n",
    "Xdata = np.load(\"Dataset/Xdata.npy\")\n",
    "Ydata = np.load(\"Dataset/Ydata.npy\")\n",
    "print(f\"the shape of input image matrix is {Xdata.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 385 #sample number\n",
    "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
    "ax[0].imshow(Xdata[n,:,:,:3].transpose((0, 1, 2)))\n",
    "ax[1].imshow(Ydata[n,:,:,0])\n",
    "\n",
    "ax[0].ticklabel_format(useOffset=False, style='plain')\n",
    "ax[1].ticklabel_format(useOffset=False, style='plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Xdata, Ydata, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet('resnet34', classes=1, activation='sigmoid')\n",
    "#https://segmentation-models.readthedocs.io/en/latest/tutorial.html\n",
    "Unet(backbone_name='resnet34',classes=1, activation='sigmoid', encoder_weights=None, input_shape=(256, 256, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model for training.\n",
    "# We use the \"sparse\" version of categorical_crossentropy\n",
    "# because our target data is integers.\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.MeanIoU(num_classes=2),tf.keras.metrics.Precision(),tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "def trainmodel(model,xdata,ydata):\n",
    "    \n",
    "    NUMBER_EPOCHS = 100\n",
    "    filepath='checkpointMaping'\n",
    "    BATCH_SIZE=32\n",
    "    \n",
    "    model_checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"min\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None\n",
    "    )\n",
    "    print(type(xdata),type(ydata))\n",
    "    hist = model.fit(x=xdata,\n",
    "                     y=ydata,\n",
    "                     epochs=NUMBER_EPOCHS,\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     validation_split=0.2,#auto validate using 20% of random samples at each epoch\n",
    "                     verbose=1, callbacks=[model_checkpoint_callback],class_weight = {0: 1, 1: 5}\n",
    "\n",
    "                    )\n",
    "    return hist\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
