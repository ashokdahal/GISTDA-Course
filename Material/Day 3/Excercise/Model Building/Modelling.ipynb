{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the pre-processed data in previous data preparation notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: Dataset: File exists\n",
      "zsh:1: no matches found: https://zenodo.org/records/12751419/files/XDataPrichit.npy?download=1\n",
      "zsh:1: no matches found: https://zenodo.org/records/12751419/files/YDataPrichit.npy?download=1\n"
     ]
    }
   ],
   "source": [
    "# Download Ground Truth\n",
    "!mkdir Dataset\n",
    "!wget  https://zenodo.org/records/12751419/files/XDataPrichit.npy?download=1  -O Dataset/Xdata.npy\n",
    "!wget  https://zenodo.org/records/12751419/files/YDataPrichit.npy?download=1  -O Dataset/Ydata.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSM_FRAMEWORK\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import keras\n",
    "\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "\n",
    "keras.backend.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and divide dataset\n",
    "Xdata = np.load(\"Dataset/Xdata.npy\").transpose(0, 2, 3, 1)\n",
    "Ydata = np.load(\"Dataset/Ydata.npy\").transpose(0, 2, 3, 1)\n",
    "print(f\"the shape of input image matrix is {Xdata.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1354  # sample number\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(Xdata[n, :, :, 6])\n",
    "ax[1].imshow(Ydata[n, :, :, 0])\n",
    "\n",
    "ax[0].ticklabel_format(useOffset=False, style=\"plain\")\n",
    "ax[1].ticklabel_format(useOffset=False, style=\"plain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Xdata, Ydata, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Size of XTrain is {X_train.shape}\")\n",
    "print(f\" Size of XTest is {X_test.shape}\")\n",
    "print(f\" Size of YTrain is {y_train.shape}\")\n",
    "print(f\" Size of YTest is {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = sm.Unet('resnet34', classes=1, activation='sigmoid')\n",
    "# https://segmentation-models.readthedocs.io/en/latest/tutorial.html\n",
    "model = Unet(\n",
    "    backbone_name=\"resnet34\",\n",
    "    classes=1,\n",
    "    activation=\"sigmoid\",\n",
    "    encoder_weights=None,\n",
    "    input_shape=(256, 256, 9),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model for training.\n",
    "# We use the \"sparse\" version of categorical_crossentropy\n",
    "# because our target data is integers.\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.AUC(),\n",
    "        tf.keras.metrics.MeanIoU(num_classes=2),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def trainmodel(model, xdata, ydata):\n",
    "    NUMBER_EPOCHS = 10\n",
    "    filepath = \"checkpointMaping\"\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"min\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None,\n",
    "    )\n",
    "    print(type(xdata), type(ydata))\n",
    "    hist = model.fit(\n",
    "        x=xdata,\n",
    "        y=ydata,\n",
    "        epochs=NUMBER_EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.2,  # auto validate using 20% of random samples at each epoch\n",
    "        verbose=1,\n",
    "        callbacks=[model_checkpoint_callback],\n",
    "        class_weight={0: 1, 1: 5},\n",
    "    )\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmodel(\n",
    "    model,\n",
    "    np.array(X_train, dtype=np.float32),\n",
    "    np.expand_dims(np.array(y_train, dtype=np.float32), axis=-1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for all images in the validation set\n",
    "\n",
    "val_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = val_preds\n",
    "preds[preds > 0.50] = 1\n",
    "preds[preds <= 0.50] = 0\n",
    "sklearn.metrics.accuracy_score(y_test.flatten(), preds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = val_preds\n",
    "preds[preds > 0.50] = 1\n",
    "preds[preds <= 0.50] = 0\n",
    "sklearn.metrics.f1_score(y_test.flatten(), preds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 235  # sample number\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "im1 = ax[0].imshow(\n",
    "    val_preds[n, :, :, :3].transpose((0, 1, 2)), vmin=0, vmax=0.5, cmap=\"plasma\"\n",
    ")\n",
    "im2 = ax[1].imshow(y_test[n, :, :, 0], cmap=\"plasma\")\n",
    "ax[0].ticklabel_format(useOffset=False, style=\"plain\")\n",
    "ax[1].ticklabel_format(useOffset=False, style=\"plain\")\n",
    "\n",
    "fig.colorbar(im1, ax=ax[0])\n",
    "fig.colorbar(im2, ax=ax[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
